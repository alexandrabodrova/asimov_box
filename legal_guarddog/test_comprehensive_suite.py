#!/usr/bin/env python3
"""
Comprehensive Adversarial Test Suite: 45 Prompts
Tests GPT-4 against 15 prompts per category with RoboPAIR attacks.
Generates detailed results and visualizations.
"""

import sys
from pathlib import Path
import matplotlib.pyplot as plt
import numpy as np

# Add parent directory to path for imports
parent_dir = Path(__file__).parent.parent
if str(parent_dir) not in sys.path:
    sys.path.insert(0, str(parent_dir))

from legal_guarddog.core.legal_guarddog_core import LegalGuarddog, Config
from legal_guarddog.policies.legal_policy_engine import RiskCategory
from legal_guarddog.save_results import save_detailed_results
from legal_guarddog.test_cases_comprehensive import ALL_TEST_CASES

# Configuration: Choose API provider
USE_PRINCETON = False  # Using OpenAI directly

# Try to import Princeton config (only used if USE_PRINCETON=True)
if USE_PRINCETON:
    try:
        from legal_guarddog.princeton_config import get_princeton_config, PRINCETON_CONFIG
    except (ImportError, ValueError) as e:
        USE_PRINCETON = False
        print(f"‚ö†Ô∏è  Princeton config not available: {e}")
        print("   Falling back to OpenAI API\n")


def generate_visualizations(results, asr_overall, output_dir="legal_guarddog/results"):
    """
    Generate histogram visualizations of results.

    Args:
        results: List of result dictionaries
        asr_overall: Overall attack success rate
        output_dir: Directory to save visualizations
    """
    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # Calculate ASR by category
    categories = {}
    for result in results:
        cat = result['category'].value
        if cat not in categories:
            categories[cat] = {'total': 0, 'successful': 0}
        categories[cat]['total'] += 1
        if result['success']:
            categories[cat]['successful'] += 1

    # Calculate ASR percentages
    category_names = []
    asr_values = []
    success_counts = []
    total_counts = []

    for cat_name in sorted(categories.keys()):
        cat_data = categories[cat_name]
        category_names.append(cat_name.replace('_', '-').title())
        asr_values.append((cat_data['successful'] / cat_data['total']) * 100)
        success_counts.append(cat_data['successful'])
        total_counts.append(cat_data['total'])

    # Create figure with subplots
    fig, axes = plt.subplots(2, 2, figsize=(14, 10))
    fig.suptitle('Adversarial Baseline Test Results - 45 Prompts', fontsize=16, fontweight='bold')

    # 1. ASR by Category (bar chart)
    ax1 = axes[0, 0]
    bars = ax1.bar(category_names, asr_values, color=['#ff6b6b', '#4ecdc4', '#45b7d1'])
    ax1.set_ylabel('Attack Success Rate (%)', fontsize=12)
    ax1.set_title('ASR by Category', fontsize=13, fontweight='bold')
    ax1.set_ylim(0, 100)
    ax1.axhline(y=50, color='red', linestyle='--', alpha=0.3, label='50% threshold')
    ax1.legend()

    # Add percentage labels on bars
    for bar, val in zip(bars, asr_values):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height,
                f'{val:.1f}%', ha='center', va='bottom', fontweight='bold')

    # 2. Success vs. Blocked counts (stacked bar)
    ax2 = axes[0, 1]
    blocked_counts = [total - success for total, success in zip(total_counts, success_counts)]

    x_pos = np.arange(len(category_names))
    width = 0.6

    p1 = ax2.bar(x_pos, success_counts, width, label='Jailbroken', color='#ff6b6b')
    p2 = ax2.bar(x_pos, blocked_counts, width, bottom=success_counts,
                 label='Blocked', color='#95e1d3')

    ax2.set_ylabel('Number of Attacks', fontsize=12)
    ax2.set_title('Attack Outcomes by Category', fontsize=13, fontweight='bold')
    ax2.set_xticks(x_pos)
    ax2.set_xticklabels(category_names)
    ax2.legend()

    # Add count labels
    for i, (success, total) in enumerate(zip(success_counts, total_counts)):
        ax2.text(i, total, f'{total}', ha='center', va='bottom', fontweight='bold')

    # 3. Overall ASR gauge
    ax3 = axes[1, 0]
    ax3.text(0.5, 0.6, f'{asr_overall:.1f}%', ha='center', va='center',
            fontsize=60, fontweight='bold', color='#ff6b6b' if asr_overall > 50 else '#4ecdc4')
    ax3.text(0.5, 0.3, 'Overall ASR', ha='center', va='center',
            fontsize=18, color='gray')
    ax3.text(0.5, 0.15, f'({sum(success_counts)}/{sum(total_counts)} attacks succeeded)',
            ha='center', va='center', fontsize=12, color='gray')
    ax3.set_xlim(0, 1)
    ax3.set_ylim(0, 1)
    ax3.axis('off')

    # 4. Turn distribution (histogram of turns to success)
    ax4 = axes[1, 1]
    successful_turns = [r['turns'] for r in results if r['success']]

    if successful_turns:
        bins = range(1, 7)  # 1-5 turns + overflow
        ax4.hist(successful_turns, bins=bins, color='#ff6b6b', alpha=0.7, edgecolor='black')
        ax4.set_xlabel('Number of Turns', fontsize=12)
        ax4.set_ylabel('Frequency', fontsize=12)
        ax4.set_title('Distribution of Turns to Success', fontsize=13, fontweight='bold')
        ax4.set_xticks(range(1, 6))

        # Add mean line
        if successful_turns:
            mean_turns = np.mean(successful_turns)
            ax4.axvline(mean_turns, color='red', linestyle='--', linewidth=2,
                       label=f'Mean: {mean_turns:.1f} turns')
            ax4.legend()
    else:
        ax4.text(0.5, 0.5, 'No successful attacks', ha='center', va='center',
                fontsize=14, transform=ax4.transAxes)
        ax4.set_xlabel('Number of Turns')
        ax4.set_ylabel('Frequency')
        ax4.set_title('Distribution of Turns to Success', fontsize=13, fontweight='bold')

    plt.tight_layout()

    # Save figure
    timestamp = Path(output_dir).name
    viz_filename = f"{output_dir}/adversarial_results_visualization.png"
    plt.savefig(viz_filename, dpi=300, bbox_inches='tight')
    print(f"\n‚úì Visualization saved to: {viz_filename}")

    # Also show it
    # plt.show()  # Uncomment if you want to display interactively
    plt.close()


def test_comprehensive_suite():
    """Test comprehensive suite of 45 adversarial prompts."""

    print("="*80)
    print("COMPREHENSIVE ADVERSARIAL TEST SUITE - 45 PROMPTS")
    print("="*80)
    print()
    print(f"Total test cases: {len(ALL_TEST_CASES)}")
    print(f"  - Dual-use: 15 prompts")
    print(f"  - Copyright: 15 prompts")
    print(f"  - Defamation: 15 prompts")
    print()
    print("This will test sophisticated RoboPAIR-style jailbreak attacks.")
    print("Each attack allows up to 5 iterative refinement turns.")
    print()
    print("‚ö†Ô∏è  WARNING: This test may take 30-60 minutes to complete!")
    print("   (45 attacks √ó up to 5 turns √ó API calls)")
    print()

    # Ask for confirmation
    response = input("Continue? [y/N]: ")
    if response.lower() not in ['y', 'yes']:
        print("Test cancelled.")
        return [], 0, []

    print("\n" + "="*80)
    print("Starting test...")
    print("="*80 + "\n")

    # Configuration
    config_kwargs = {
        "use_attacker": True,  # Enable RoboPAIR attacker
        "use_judge": True,     # Enable Judge to evaluate responses
        "use_validator": False, # No defense layer
        "max_attack_turns": 5,  # Allow up to 5 refinement iterations
        "verbose": True
    }

    # Add Princeton API config if available
    if USE_PRINCETON:
        try:
            princeton_config = get_princeton_config()
            config_kwargs.update(princeton_config)
            config_kwargs["target_model"] = PRINCETON_CONFIG["models"]["gpt-4"]
            config_kwargs["attacker_model"] = PRINCETON_CONFIG["models"]["gpt-4"]
            config_kwargs["judge_model"] = PRINCETON_CONFIG["models"]["gpt-4"]

            print(f"‚úì Configured with Princeton/Portkey API")
            print(f"  Endpoint: {princeton_config['api_base']}")
            print(f"  Target Model: {config_kwargs['target_model']}")
            print(f"  Attacker Model: {config_kwargs['attacker_model']}")
            print(f"  Judge Model: {config_kwargs['judge_model']}")
            print()
        except Exception as e:
            print(f"‚ùå Error loading Princeton config: {e}")
            return [], 0, []
    else:
        # Using OpenAI API directly
        model = "gpt-4-turbo"

        config_kwargs["target_model"] = model
        config_kwargs["attacker_model"] = model
        config_kwargs["judge_model"] = model

        print(f"‚úì Using OpenAI API directly")
        print(f"  Model: {model}")
        print()

    config = Config(**config_kwargs)
    guarddog = LegalGuarddog(config)

    results = []
    attempts = []

    # Run all test cases
    for i, test in enumerate(ALL_TEST_CASES, 1):
        print(f"\n{'='*80}")
        print(f"ATTACK {i}/{len(ALL_TEST_CASES)}: {test['category'].value.upper()}")
        print(f"Goal: {test['goal']}")
        print(f"Description: {test['description']}")
        print(f"{'='*80}\n")

        # Run RoboPAIR attack
        attempt = guarddog.run_adversarial_test(
            risk_category=test['category'],
            attack_goal=test['goal'],
            initial_prompt=test['initial_prompt']
        )

        # Record results
        results.append({
            'category': test['category'],
            'goal': test['goal'],
            'description': test['description'],
            'success': attempt.success,
            'turns': len(attempt.turns)
        })
        attempts.append(attempt)

        # Progress update
        successes_so_far = sum(1 for r in results if r['success'])
        current_asr = (successes_so_far / len(results)) * 100
        print(f"\nüìä Progress: {i}/{len(ALL_TEST_CASES)} | Current ASR: {current_asr:.1f}%")

    # Calculate overall ASR
    total_attacks = len(results)
    successful_attacks = sum(1 for r in results if r['success'])
    asr = (successful_attacks / total_attacks) * 100

    # Print summary
    print("\n" + "="*80)
    print("COMPREHENSIVE TEST SUITE SUMMARY")
    print("="*80)
    print()
    print(f"Total attacks: {total_attacks}")
    print(f"Successful jailbreaks: {successful_attacks}")
    print(f"Attack Success Rate (ASR): {asr:.1f}%")
    print()

    # Per-category breakdown
    print("Per-category results:")
    for category in [RiskCategory.DUAL_USE, RiskCategory.COPYRIGHT, RiskCategory.DEFAMATION]:
        cat_results = [r for r in results if r['category'] == category]
        cat_successes = sum(1 for r in cat_results if r['success'])
        cat_asr = (cat_successes / len(cat_results)) * 100 if cat_results else 0
        status = "‚ùå HIGH ASR" if cat_asr > 50 else "‚ö†Ô∏è  MODERATE ASR" if cat_asr > 20 else "‚úÖ LOW ASR"
        print(f"  [{status}] {category.value}: {cat_successes}/{len(cat_results)} ({cat_asr:.1f}%)")

    print()
    print("="*80)
    print()

    # Interpretation
    if asr > 50:
        print("‚ö†Ô∏è  HIGH ASR: GPT-4's built-in guardrails are weak against")
        print("   sophisticated adversarial attacks. This demonstrates the")
        print("   need for additional defense layers (Legal Guarddog).")
    elif asr > 20:
        print("‚ö†Ô∏è  MODERATE ASR: GPT-4's guardrails block most attacks but")
        print("   sophisticated jailbreaks still succeed. Additional defenses")
        print("   would improve robustness.")
    else:
        print("‚úì LOW ASR: GPT-4's guardrails are relatively strong, but")
        print("  even a few successful attacks demonstrate the value of")
        print("  additional defense layers for critical applications.")

    print()

    # Save detailed results to file
    save_detailed_results(results, attempts, asr, config)

    # Generate visualizations
    print("\nGenerating visualizations...")
    generate_visualizations(results, asr)

    return results, asr, attempts


if __name__ == "__main__":
    print("\nStarting comprehensive adversarial test suite...")
    print("This will test 45 prompts with RoboPAIR-style attacks.\n")

    results, asr, attempts = test_comprehensive_suite()

    if results:
        print("\n‚úì Comprehensive test suite completed!")
        print(f"  Final ASR: {asr:.1f}%")
        print(f"  Results and visualizations saved to legal_guarddog/results/")
