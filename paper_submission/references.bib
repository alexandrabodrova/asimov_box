@article{lemley2024copyright,
  author = {Mark A. Lemley},
  title = {How Generative {AI} Turns Copyright Upside Down},
  journal = {Stanford Science \& Technology Law Review},
  volume = {25},
  year = {2024},
  url = {https://law.stanford.edu/wp-content/uploads/2024/09/2024-09-30_How-Gerative-AI-Turns-Copyright-Upside-Down.pdf}
}

@inproceedings{chao2024jailbreakbench,
  author = {Patrick Chao and Edoardo Debenedetti and Alexander Robey and Maksym Andriushchenko and Francesco Croce and Vikash Sehwag and Edgar Dobriban and Nicolas Flammarion and George J. Pappas and Florian Tram{\`e}r and Hamed Hassani and Eric Wong},
  title = {{JailbreakBench}: An Open Robustness Benchmark for Jailbreaking Large Language Models},
  booktitle = {NeurIPS 2024 Datasets and Benchmarks Track},
  year = {2024},
  url = {https://arxiv.org/abs/2404.01318}
}

@inproceedings{robey2024jailbreaking,
  author = {Alexander Robey and Zachary Ravichandran and Vijay Kumar and Hamed Hassani and George J. Pappas},
  title = {Jailbreaking {LLM}-Controlled Robots},
  booktitle = {Proceedings of the IEEE International Conference on Robotics and Automation (ICRA 2025)},
  year = {2024},
  note = {preprint},
  url = {https://arxiv.org/abs/2410.13691}
}

@article{volokh2023libel,
  author = {Eugene Volokh},
  title = {Large Libel Models? {L}iability for {AI} Output},
  journal = {Journal of Free Speech Law},
  volume = {3},
  pages = {489--559},
  year = {2023},
  url = {https://www.journaloffreespeechlaw.org/volokh4.pdf}
}

@article{ravichandran2024safety,
  author = {Zachary Ravichandran and Alexander Robey and Vijay Kumar and George J. Pappas and Hamed Hassani},
  title = {Safety Guardrails for {LLM}-Enabled Robots},
  journal = {arXiv preprint},
  year = {2025},
  url = {https://arxiv.org/abs/2503.07885}
}

@misc{uscopyright2025,
  author = {{U.S. Copyright Office}},
  title = {Copyright and Artificial Intelligence},
  year = {2025},
  url = {https://www.copyright.gov/ai/}
}

@article{wachter2024duty,
  author = {Sandra Wachter and Brent Mittelstadt and Chris Russell},
  title = {Do Large Language Models Have a Legal Duty to Tell the Truth?},
  journal = {Royal Society Open Science},
  volume = {11},
  number = {8},
  pages = {240197},
  year = {2024},
  doi = {10.1098/rsos.240197},
  url = {https://pubmed.ncbi.nlm.nih.gov/39113763/}
}

@article{gstrein2024gpai,
  author = {Oskar J. Gstrein and Noor Haleem and Andrej Zwitter},
  title = {General-Purpose {AI} Regulation and the {E}uropean {U}nion {AI} {A}ct},
  journal = {Internet Policy Review},
  volume = {13},
  number = {3},
  year = {2024},
  doi = {10.14763/2024.3.1790},
  url = {https://policyreview.info/articles/analysis/general-purpose-ai-regulation-and-ai-act}
}

@article{beyer2025llmsafety,
  author = {Timo Beyer and Samuel Xhonneux and Simon Geisler and Gauthier Gidel and Leo Schwinn and Stephan G{\"u}nnemann},
  title = {{LLM}-Safety Evaluations Lack Robustness},
  journal = {arXiv preprint (arXiv:2503.02574)},
  year = {2025},
  url = {https://arxiv.org/abs/2503.02574}
}

@article{inan2023llama,
  author = {Hakan Inan and Kartikeya Upasani and Jianfeng Chi and Rashi Rungta and Krithika Iyer and Yuning Mao and Michael Tontchev and Qing Hu and Brian Fuller and Davide Testuggine and Madian Khabsa},
  title = {{Llama Guard}: {LLM}-Based Input--Output Safeguard for Human--{AI} Conversations},
  journal = {arXiv preprint (arXiv:2312.06674)},
  year = {2023},
  url = {https://arxiv.org/abs/2312.06674}
}

@inproceedings{rebedea2023nemo,
  author = {Traian Rebedea and Razvan Dinu and Makesh Sreedhar and Christopher Parisien and Jonathan Cohen},
  title = {{NeMo Guardrails}: A Toolkit for Controllable and Safe {LLM} Applications with Programmable Rails},
  booktitle = {Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: System Demonstrations (EMNLP 2023 Demos)},
  year = {2023},
  url = {https://aclanthology.org/2023.emnlp-demo.40/}
}

@article{liu2023prompt,
  author = {Yi Liu and Gelei Deng and Yuekang Li and Kailong Wang and Zihao Wang and Xiaofeng Wang and Tianwei Zhang and Yepang Liu and Haoyu Wang and Yan Zheng and Yang Liu},
  title = {Prompt Injection Attack Against {LLM}-Integrated Applications},
  journal = {arXiv preprint (arXiv:2306.05499)},
  year = {2023},
  note = {rev. 2024},
  url = {https://arxiv.org/abs/2306.05499}
}

@article{zou2023universal,
  author = {Andy Zou and Zifan Wang and J. Zico Kolter and Matt Fredrikson},
  title = {Universal and Transferable Adversarial Attacks on Aligned Language Models},
  journal = {arXiv preprint (arXiv:2307.15043)},
  year = {2023},
  url = {https://arxiv.org/abs/2307.15043}
}

@article{cooper2024generative,
  author = {A. Feder Cooper and Katherine Lee and James Grimmelmann},
  title = {Generative {AI} and Copyright's Economies of Scale},
  journal = {Journal of the Copyright Society of the USA},
  year = {2024},
  url = {https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4827042}
}

@article{henderson2024foundation,
  author = {Peter Henderson and others},
  title = {Foundation Model Transparency Reports},
  journal = {arXiv preprint (arXiv:2402.16268)},
  year = {2024},
  url = {https://arxiv.org/abs/2402.16268}
}

@article{urban2024generative,
  author = {Jennifer M. Urban and others},
  title = {Generative {AI}, Copyright, and the Law},
  journal = {Berkeley Technology Law Journal},
  year = {2024},
  url = {https://arxiv.org/abs/2505.12546}
}

@inproceedings{carlini2023extracting,
  author = {Nicholas Carlini and others},
  title = {Extracting Training Data from Large Language Models},
  booktitle = {USENIX Security Symposium},
  year = {2023},
  url = {https://www.usenix.org/conference/usenixsecurity23/presentation/carlini-extracting}
}

@article{shen2024anything,
  author = {Yueqi Shen and others},
  title = {``Do Anything Now'': Characterizing and Evaluating In-The-Wild Jailbreak Prompts on Large Language Models},
  journal = {arXiv preprint (arXiv:2308.03825)},
  year = {2024},
  url = {https://arxiv.org/abs/2308.03825}
}

@misc{walters2023defamation,
  author = {Mark Walters},
  title = {Walters v. {OpenAI}},
  year = {2023},
  note = {Defamation claim against AI-generated false information}
}

@misc{tremblay2023complaint,
  author = {Paul Tremblay and Mona Awad},
  title = {Tremblay v. {OpenAI}, Inc.},
  year = {2023},
  note = {U.S. District Court, N.D. California, Case 3:23-cv-03223}
}

@misc{silverman2023complaint,
  author = {Sarah Silverman and Christopher Golden and Richard Kadrey},
  title = {Silverman v. Meta Platforms, Inc.},
  year = {2023},
  note = {U.S. District Court, N.D. California, Case 3:23-cv-03416}
}

@misc{euaiact2024,
  author = {{European Commission}},
  title = {The {AI} Act},
  year = {2024},
  url = {https://digital-strategy.ec.europa.eu/en/policies/regulatory-framework-ai}
}

@article{bender2021dangers,
  author = {Emily M. Bender and Timnit Gebru and Angelina McMillan-Major and Shmargaret Shmitchell},
  title = {On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?},
  booktitle = {Proceedings of FAccT 2021},
  year = {2021},
  url = {https://dl.acm.org/doi/10.1145/3442188.3445922}
}

@article{carlini2021extracting,
  author = {Nicholas Carlini and Florian Tram{\`e}r and Eric Wallace and Matthew Jagielski and Ariel Herbert-Voss and Katherine Lee and Adam Roberts and Tom Brown and Dawn Song and {\'U}lfar Erlingsson and Alina Oprea and Colin Raffel},
  title = {Extracting Training Data from Large Language Models},
  journal = {USENIX Security},
  year = {2021},
  url = {https://arxiv.org/abs/2012.07805}
}

@article{wei2024jailbroken,
  author = {Alexander Wei and Nika Haghtalab and Jacob Steinhardt},
  title = {Jailbroken: How Does {LLM} Safety Training Fail?},
  journal = {NeurIPS},
  year = {2024},
  url = {https://arxiv.org/abs/2307.02483}
}
